{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "audio_file_path = \"\"\n",
    "\n",
    "audio_file = open(audio_file_path, \"rb\")\n",
    "transcript = client.audio.transcriptions.create(\n",
    "  file=audio_file,\n",
    "  model=\"whisper-1\",\n",
    "  response_format=\"verbose_json\",\n",
    "  timestamp_granularities=[\"word\"]\n",
    ")\n",
    "\n",
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_stuttering(transcription):\n",
    "    \"\"\"\n",
    "    Analyze the transcription for stuttering patterns using OpenAI's GPT API.\n",
    "    \"\"\"\n",
    "    # Extract word-level data from the transcription object\n",
    "    words = transcription.words\n",
    "    word_data = [\n",
    "        {\n",
    "            \"word\": word.word,\n",
    "            \"start\": word.start,\n",
    "            \"end\": word.end\n",
    "        }\n",
    "        for word in words\n",
    "    ]\n",
    "\n",
    "    # Prepare the prompt with structured word data\n",
    "    prompt = f\"\"\"As a speech analysis expert, analyze this transcription for stuttering patterns. \n",
    "    Each word has a start and end timestamp. Look for:\n",
    "    1. Word repetitions\n",
    "    2. Sound prolongations\n",
    "    3. Blocks of silence or broken words\n",
    "    4. Interjections or fillers when struggling with words\n",
    "    5. Revision patterns or abandoned phrases\n",
    "    \n",
    "    Here is the transcription data:\n",
    "    {word_data}\n",
    "    \n",
    "    Provide your analysis in JSON format with the following structure:\n",
    "    {{\n",
    "        \"stutter_instances\": [\n",
    "            {{\n",
    "                \"timestamp\": [start_time, end_time]\n",
    "            }}\n",
    "        ]\n",
    "    }}\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a speech analysis expert specializing in detecting speech disfluencies and stuttering patterns.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=messages,\n",
    "        temperature=0.3,\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "response_json = analyze_stuttering(transcript)\n",
    "\n",
    "start_index = response_json.find(\"{\")  # Find where the JSON starts\n",
    "json_string = response_json[start_index:]  # Extract everything from that point onward\n",
    "\n",
    "# Parse the JSON string into a Python dictionary\n",
    "json_object = json.loads(json_string)\n",
    "\n",
    "# Print or use the extracted JSON object\n",
    "print(json_object)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
